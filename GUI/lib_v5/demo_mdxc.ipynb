{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEN2Ei3D284H"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkv0g0H0yNA4"
      },
      "outputs": [],
      "source": [
        "from mdx.tfc_tdf_v3 import TFC_TDF_net, STFT\n",
        "from mdx.tfc_tdf_v3 import TFC_TDF_net, STFT\n",
        "import mdx.mdxnet as MdxnetSet\n",
        "from mdx import spec_utils\n",
        "from mdx.constants import secondary_stem\n",
        "import onnxruntime as ort\n",
        "from onnx import load\n",
        "from onnx2pytorch import ConvertModel\n",
        "from ml_collections import ConfigDict\n",
        "\n",
        "import torch\n",
        "import audiofile\n",
        "from IPython.display import Audio, display\n",
        "import soundfile as sf\n",
        "import json \n",
        "import hashlib\n",
        "import librosa\n",
        "import numpy as np\n",
        "import audioread\n",
        "import platform\n",
        "from numpy.typing import NDArray\n",
        "from typing import Union\n",
        "import math, os\n",
        "import yaml\n",
        "\n",
        "if torch.cuda.is_available(): device = \"cuda\"\n",
        "elif torch.backends.mps.is_available(): device = torch.device(\"mps\")\n",
        "else: device = \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhWOPekI3IbK"
      },
      "source": [
        "# Main code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load model config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def load_mdxc_models_data(model_path:str=\"mdxc/modelparams/model_data.json\")->dict:\n",
        "    \"\"\"\n",
        "    Load the mdxc models data from the specified model path.\n",
        "\n",
        "    Args:\n",
        "        model_path (str): The path to the model data JSON file. Default is \"mdxc/modelparams/model_data.json\".\n",
        "\n",
        "    Returns:\n",
        "        dict: The loaded models data.\n",
        "    \"\"\"\n",
        "\n",
        "    models_data = json.load(open(model_path))\n",
        "    return models_data\n",
        "\n",
        "\n",
        "def get_model_hash_from_path(model_path:str=\"./mdxc/weights/MDX23C-8KFFT-InstVoc_HQ/MDX23C-8KFFT-InstVoc_HQ.ckpt\")->str:\n",
        "    \"\"\"\n",
        "    Get the hash of the model from the specified model path.\n",
        "\n",
        "    Args:\n",
        "        model_path (str): The path to the model file. Default is \"./mdxc/weights/UVR-MDX-NET-Inst_1/UVR-MDX-NET-Inst_1.ckpt\".\n",
        "\n",
        "    Returns:\n",
        "        str: The hash of the model.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        with open(model_path, 'rb') as f:\n",
        "            f.seek(- 10000 * 1024, 2)\n",
        "            model_hash = hashlib.md5(f.read()).hexdigest()\n",
        "    except:\n",
        "        model_hash = hashlib.md5(open(model_path,'rb').read()).hexdigest()\n",
        "    \n",
        "    return model_hash\n",
        "\n",
        "\n",
        "def load_mdxc_model_data(models_data, model_hash, model_path=\"./mdxc/modelparams\")->ConfigDict:\n",
        "    \"\"\"\n",
        "    Load the mdxc model data from the specified models data and model hash.\n",
        "\n",
        "    Args:\n",
        "        models_data (dict): The models data.\n",
        "        model_hash (str): The hash of the model.\n",
        "\n",
        "    Returns:\n",
        "        dict: The loaded model data.\n",
        "    \"\"\"\n",
        "\n",
        "    model_data_src = models_data[model_hash]\n",
        "    # if not \"config_yaml\" in model_data_src: return model_data_src\n",
        "    model_path = os.path.join(model_path, \"mdx_c_configs\", model_data_src['config_yaml'])\n",
        "    model_data = yaml.load(open(model_path), Loader=yaml.FullLoader)\n",
        "\n",
        "    model_data = ConfigDict(model_data)\n",
        "    \n",
        "    return model_data\n",
        "\n",
        "models_data = load_mdxc_models_data(model_path=\"mdxc/modelparams/model_data.json\")\n",
        "model_hash = get_model_hash_from_path(model_path=\"./mdxc/weights/MDX23C-8KFFT-InstVoc_HQ/MDX23C-8KFFT-InstVoc_HQ.ckpt\")\n",
        "\n",
        "model_data = models_data[model_hash]\n",
        "\n",
        "model_data = load_mdxc_model_data(models_data, model_hash, model_path=\"./mdxc/modelparams\")\n",
        "\n",
        "\n",
        "model_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_modle(model_path:str, model_data:ConfigDict, device:str='cuda')->torch.nn.Module:\n",
        "    \"\"\"\n",
        "    Load the model from the given path and return the loaded model.\n",
        "\n",
        "    Args:\n",
        "        model_path (str): The path to the model file.\n",
        "        model_data (ConfigDict): The model data.\n",
        "        device (str): The device to load the model on. Defaults to 'cuda'.\n",
        "\n",
        "    Returns:\n",
        "        model_run (function): The loaded model.\n",
        "\n",
        "    \"\"\"\n",
        "    model = TFC_TDF_net(model_data, device=device)\n",
        "    model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
        "    model.to(device).eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "model_run = load_modle(\"./mdxc/weights/MDX23C-8KFFT-InstVoc_HQ/MDX23C-8KFFT-InstVoc_HQ.ckpt\",\n",
        "                       model_data, device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def rerun_mp3(audio_file:NDArray, sample_rate:int=44100):\n",
        "    \"\"\"\n",
        "    Load an audio file and return the audio data.\n",
        "\n",
        "    Parameters:\n",
        "        audio_file (str): The path to the audio file.\n",
        "        sample_rate (int, optional): The desired sample rate of the audio data. Default is 44100.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The audio data as a numpy array.\n",
        "    \"\"\"\n",
        "    with audioread.audio_open(audio_file) as f:\n",
        "        track_length = int(f.duration)\n",
        "\n",
        "    return librosa.load(audio_file, duration=track_length, mono=False, sr=sample_rate)[0]\n",
        "\n",
        "def prepare_mix(mix):\n",
        "    \n",
        "    audio_path = mix\n",
        "\n",
        "    if not isinstance(mix, np.ndarray):\n",
        "        mix, sr = librosa.load(mix, mono=False, sr=44100)\n",
        "    else:\n",
        "        mix = mix.T\n",
        "\n",
        "    if isinstance(audio_path, str):\n",
        "        if not np.any(mix) and audio_path.endswith('.mp3'):\n",
        "            mix = rerun_mp3(audio_path)\n",
        "\n",
        "    if mix.ndim == 1:\n",
        "        mix = np.asfortranarray([mix,mix])\n",
        "\n",
        "    return mix\n",
        "\n",
        "\n",
        "\n",
        "audio_file = \"/Users/mohannadbarakat/Downloads/t.wav\"\n",
        "mix = prepare_mix(audio_file)\n",
        "mix.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pitch_fix(source, sr_pitched, org_mix, semitone_shift)->np.ndarray:\n",
        "    source = spec_utils.change_pitch_semitones(source, sr_pitched, semitone_shift=semitone_shift)[0]\n",
        "    source = spec_utils.match_array_shapes(source, org_mix)\n",
        "    return source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "segment_size = 256\n",
        "prams = {\n",
        "    'is_mdx_c_seg_def': False,\n",
        "    'segment_size': segment_size,\n",
        "    'batch_size': 1,\n",
        "    'overlap_mdx23': 8,\n",
        "    'semitone_shift': 0,\n",
        "    # 'mdx_segment_size': segment_size\n",
        "}\n",
        "\n",
        "\n",
        "def demix(mix:np.ndarray, prams:dict, model:torch.nn.Module, model_data:ConfigDict, device:str='cpu')->dict:\n",
        "    \"\"\"\n",
        "    Demixes the input audio mixture into its constituent sources using a given model.\n",
        "\n",
        "    Args:\n",
        "        mix (np.ndarray): The input audio mixture.\n",
        "        prams (dict): A dictionary containing various parameters for demixing.\n",
        "        model (torch.nn.Module): The demixing model.\n",
        "        model_data (ConfigDict): The configuration data for the model.\n",
        "        device (str, optional): The device to run the demixing on. Defaults to 'cpu'.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the estimated sources.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    sr_pitched = 441000\n",
        "    org_mix = mix\n",
        "    semitone_shift = prams['semitone_shift']\n",
        "    if  semitone_shift != 0:\n",
        "        mix, sr_pitched = spec_utils.change_pitch_semitones(mix, 44100, semitone_shift=-semitone_shift)\n",
        "\n",
        "    \n",
        "    mix = torch.tensor(mix, dtype=torch.float32)\n",
        "\n",
        "    try:\n",
        "        S = model.num_target_instruments\n",
        "    except Exception as e:\n",
        "        S = model.module.num_target_instruments\n",
        "\n",
        "    if prams['is_mdx_c_seg_def']:\n",
        "        mdx_segment_size = model_data.inference.dim_t  \n",
        "    else:\n",
        "        mdx_segment_size = prams['segment_size']\n",
        "    \n",
        "    batch_size = prams['batch_size']\n",
        "    chunk_size = model_data.audio.hop_length * (mdx_segment_size - 1)\n",
        "    overlap = prams['overlap_mdx23']\n",
        "\n",
        "    hop_size = chunk_size // overlap\n",
        "    mix_shape = mix.shape[1]\n",
        "    pad_size = hop_size - (mix_shape - chunk_size) % hop_size\n",
        "    mix = torch.cat([torch.zeros(2, chunk_size - hop_size), mix, torch.zeros(2, pad_size + chunk_size - hop_size)], 1)\n",
        "\n",
        "    chunks = mix.unfold(1, chunk_size, hop_size).transpose(0, 1)\n",
        "    batches = [chunks[i : i + batch_size] for i in range(0, len(chunks), batch_size)]\n",
        "    \n",
        "    X = torch.zeros(S, *mix.shape) if S > 1 else torch.zeros_like(mix)\n",
        "    X = X.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        cnt = 0\n",
        "        for batch in batches:\n",
        "            x = model(batch.to(device))\n",
        "            \n",
        "            for w in x:\n",
        "                X[..., cnt * hop_size : cnt * hop_size + chunk_size] += w\n",
        "                cnt += 1\n",
        "\n",
        "    estimated_sources = X[..., chunk_size - hop_size:-(pad_size + chunk_size - hop_size)] / overlap\n",
        "    del X\n",
        "    pitch_fix = lambda s:pitch_fix(s, sr_pitched, org_mix, semitone_shift)\n",
        "\n",
        "    if S > 1:\n",
        "        sources = {k: pitch_fix(v) if semitone_shift!=0 else v for k, v in zip(model_data.training.instruments, estimated_sources.cpu().detach().numpy())}\n",
        "        del estimated_sources   \n",
        "        return sources\n",
        "    \n",
        "    est_s = estimated_sources.cpu().detach().numpy()\n",
        "    del estimated_sources\n",
        "\n",
        "    if semitone_shift!=0:\n",
        "        return pitch_fix(est_s)  \n",
        "    else:\n",
        "        return est_s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stems = demix(mix, prams, model_run, model_data, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rename_stems(stems:dict)->dict:\n",
        "    \"\"\"\n",
        "    Basicly, applay .lower() to all keys in the stems dict.\n",
        "    Args:\n",
        "        stems (dict): The stems to be renamed.\n",
        "        model_data (ConfigDict): The model data.\n",
        "\n",
        "    Returns:\n",
        "        dict: The renamed stems.\n",
        "    \"\"\"\n",
        "\n",
        "    return {k.lower():v for k,v in stems.items()}\n",
        "\n",
        "stems = rename_stems(stems)\n",
        "stems.keys()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_samplerate = 44100\n",
        "path = \"vocals.wav\"\n",
        "audiofile.write(path, stems['vocals'], model_samplerate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = \"instrumental.wav\"\n",
        "audiofile.write(path, stems['instrumental'], model_samplerate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
